{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3032445907592773, Accuracy: 21.875, Test Loss: 2.3064169883728027, Test Accuracy: 11.369999885559082\n",
      "Epoch 1, Loss: 1.7134983539581299, Accuracy: 54.95049285888672, Test Loss: 1.5656007528305054, Test Accuracy: 45.75\n",
      "Epoch 1, Loss: 1.1362444162368774, Accuracy: 69.77611541748047, Test Loss: 1.1905158758163452, Test Accuracy: 59.59666442871094\n",
      "Epoch 1, Loss: 0.8882629871368408, Accuracy: 76.00706481933594, Test Loss: 0.975449800491333, Test Accuracy: 67.31749725341797\n",
      "Epoch 1, Loss: 0.7507299184799194, Accuracy: 79.48877716064453, Test Loss: 0.8346531391143799, Test Accuracy: 72.2959976196289\n",
      "Epoch 1, Loss: 0.6558398008346558, Accuracy: 81.92989349365234, Test Loss: 0.7382892370223999, Test Accuracy: 75.65167236328125\n",
      "Epoch 1, Loss: 0.5885500907897949, Accuracy: 83.71463775634766, Test Loss: 0.6642132997512817, Test Accuracy: 78.22000122070312\n",
      "Epoch 1, Loss: 0.5379213094711304, Accuracy: 85.08826446533203, Test Loss: 0.6065375804901123, Test Accuracy: 80.1937484741211\n",
      "Epoch 1, Loss: 0.497476190328598, Accuracy: 86.16182708740234, Test Loss: 0.5582141280174255, Test Accuracy: 81.8344497680664\n",
      "Epoch 1, Loss: 0.46434304118156433, Accuracy: 87.02483367919922, Test Loss: 0.5179749131202698, Test Accuracy: 83.19400024414062\n",
      "Epoch 1, Loss: 0.4347675144672394, Accuracy: 87.80594635009766, Test Loss: 0.4854339361190796, Test Accuracy: 84.27090454101562\n",
      "Epoch 1, Loss: 0.4101622700691223, Accuracy: 88.46218872070312, Test Loss: 0.45649781823158264, Test Accuracy: 85.25\n",
      "Epoch 1, Loss: 0.38910937309265137, Accuracy: 89.00655364990234, Test Loss: 0.43157196044921875, Test Accuracy: 86.09922790527344\n",
      "Epoch 1, Loss: 0.371802419424057, Accuracy: 89.46002960205078, Test Loss: 0.40925487875938416, Test Accuracy: 86.84357452392578\n",
      "Epoch 1, Loss: 0.35482630133628845, Accuracy: 89.94691467285156, Test Loss: 0.3898281455039978, Test Accuracy: 87.48799896240234\n",
      "Epoch 1, Loss: 0.3391881287097931, Accuracy: 90.38765716552734, Test Loss: 0.37188592553138733, Test Accuracy: 88.0893783569336\n",
      "Epoch 1, Loss: 0.325088232755661, Accuracy: 90.7850570678711, Test Loss: 0.3562055230140686, Test Accuracy: 88.6005859375\n",
      "Epoch 1, Loss: 0.31193679571151733, Accuracy: 91.15409851074219, Test Loss: 0.34186992049217224, Test Accuracy: 89.0683364868164\n",
      "Epoch 1, Loss: 0.30122870206832886, Accuracy: 91.43878173828125, Test Loss: 0.3292551338672638, Test Accuracy: 89.48368072509766\n",
      "Epoch 2, Loss: 0.2933325171470642, Accuracy: 91.67277526855469, Test Loss: 0.3176507353782654, Test Accuracy: 89.85850524902344\n",
      "Epoch 2, Loss: 0.2841765284538269, Accuracy: 91.93446350097656, Test Loss: 0.30697137117385864, Test Accuracy: 90.20904541015625\n",
      "Epoch 2, Loss: 0.2757968306541443, Accuracy: 92.160400390625, Test Loss: 0.2973666787147522, Test Accuracy: 90.51773071289062\n",
      "Epoch 2, Loss: 0.26755303144454956, Accuracy: 92.38712310791016, Test Loss: 0.28845614194869995, Test Accuracy: 90.80825805664062\n",
      "Epoch 2, Loss: 0.2600797116756439, Accuracy: 92.58018493652344, Test Loss: 0.2797747850418091, Test Accuracy: 91.09041595458984\n",
      "Epoch 2, Loss: 0.2532361149787903, Accuracy: 92.76883697509766, Test Loss: 0.27177193760871887, Test Accuracy: 91.35160064697266\n",
      "Epoch 2, Loss: 0.24604858458042145, Accuracy: 92.97380065917969, Test Loss: 0.26409444212913513, Test Accuracy: 91.60231018066406\n",
      "Epoch 2, Loss: 0.23995420336723328, Accuracy: 93.14222717285156, Test Loss: 0.25711920857429504, Test Accuracy: 91.825927734375\n",
      "Epoch 2, Loss: 0.23401989042758942, Accuracy: 93.30740356445312, Test Loss: 0.25065845251083374, Test Accuracy: 92.03571319580078\n",
      "Epoch 2, Loss: 0.2290773242712021, Accuracy: 93.43817901611328, Test Loss: 0.2444925457239151, Test Accuracy: 92.23345184326172\n",
      "Epoch 2, Loss: 0.22376090288162231, Accuracy: 93.5935287475586, Test Loss: 0.23895248770713806, Test Accuracy: 92.41366577148438\n",
      "Epoch 2, Loss: 0.2189749777317047, Accuracy: 93.71849822998047, Test Loss: 0.23379667103290558, Test Accuracy: 92.58000183105469\n",
      "Epoch 2, Loss: 0.21443308889865875, Accuracy: 93.844482421875, Test Loss: 0.22856362164020538, Test Accuracy: 92.74781036376953\n",
      "Epoch 2, Loss: 0.21008044481277466, Accuracy: 93.95465850830078, Test Loss: 0.22357645630836487, Test Accuracy: 92.90605926513672\n",
      "Epoch 2, Loss: 0.206373929977417, Accuracy: 94.05238342285156, Test Loss: 0.2189178317785263, Test Accuracy: 93.05912017822266\n",
      "Epoch 2, Loss: 0.20239666104316711, Accuracy: 94.16747283935547, Test Loss: 0.21471023559570312, Test Accuracy: 93.19542694091797\n",
      "Epoch 2, Loss: 0.19846880435943604, Accuracy: 94.27772521972656, Test Loss: 0.2103969305753708, Test Accuracy: 93.33027648925781\n",
      "Epoch 2, Loss: 0.1947215050458908, Accuracy: 94.3783187866211, Test Loss: 0.20643022656440735, Test Accuracy: 93.45540618896484\n",
      "Epoch 2, Loss: 0.19121584296226501, Accuracy: 94.4793930053711, Test Loss: 0.2025800198316574, Test Accuracy: 93.57868194580078\n",
      "Epoch 3, Loss: 0.1888580620288849, Accuracy: 94.54478454589844, Test Loss: 0.19904083013534546, Test Accuracy: 93.69384765625\n",
      "Epoch 3, Loss: 0.18577779829502106, Accuracy: 94.63532257080078, Test Loss: 0.1955450028181076, Test Accuracy: 93.80549621582031\n",
      "Epoch 3, Loss: 0.18300674855709076, Accuracy: 94.71810913085938, Test Loss: 0.19212788343429565, Test Accuracy: 93.91682434082031\n",
      "Epoch 3, Loss: 0.18013432621955872, Accuracy: 94.80066680908203, Test Loss: 0.18883465230464935, Test Accuracy: 94.02381134033203\n",
      "Epoch 3, Loss: 0.177157923579216, Accuracy: 94.88150787353516, Test Loss: 0.18564309179782867, Test Accuracy: 94.12581634521484\n",
      "Epoch 3, Loss: 0.1744319349527359, Accuracy: 94.95559692382812, Test Loss: 0.18278299272060394, Test Accuracy: 94.21726989746094\n",
      "Epoch 3, Loss: 0.17156709730625153, Accuracy: 95.03633880615234, Test Loss: 0.1798219084739685, Test Accuracy: 94.31155395507812\n",
      "Epoch 3, Loss: 0.16892926394939423, Accuracy: 95.11275482177734, Test Loss: 0.17700673639774323, Test Accuracy: 94.4019546508789\n",
      "Epoch 3, Loss: 0.16643232107162476, Accuracy: 95.18512725830078, Test Loss: 0.17427204549312592, Test Accuracy: 94.48893737792969\n",
      "Epoch 3, Loss: 0.16418927907943726, Accuracy: 95.24565124511719, Test Loss: 0.1717933565378189, Test Accuracy: 94.56583404541016\n",
      "Epoch 3, Loss: 0.16204097867012024, Accuracy: 95.30164337158203, Test Loss: 0.16927528381347656, Test Accuracy: 94.64836883544922\n",
      "Epoch 3, Loss: 0.1599358767271042, Accuracy: 95.35469055175781, Test Loss: 0.16692331433296204, Test Accuracy: 94.72339630126953\n",
      "Epoch 3, Loss: 0.15800675749778748, Accuracy: 95.4074935913086, Test Loss: 0.16461174190044403, Test Accuracy: 94.79568481445312\n",
      "Epoch 3, Loss: 0.15590102970600128, Accuracy: 95.46500396728516, Test Loss: 0.1624394953250885, Test Accuracy: 94.8653793334961\n",
      "Epoch 3, Loss: 0.15394467115402222, Accuracy: 95.52392578125, Test Loss: 0.16032175719738007, Test Accuracy: 94.93434143066406\n",
      "Epoch 3, Loss: 0.15219956636428833, Accuracy: 95.57048797607422, Test Loss: 0.15814580023288727, Test Accuracy: 95.00444793701172\n",
      "Epoch 3, Loss: 0.15029080212116241, Accuracy: 95.62406921386719, Test Loss: 0.1561109870672226, Test Accuracy: 95.06927490234375\n",
      "Epoch 3, Loss: 0.1483875960111618, Accuracy: 95.68141174316406, Test Loss: 0.15412241220474243, Test Accuracy: 95.13088989257812\n",
      "Epoch 3, Loss: 0.1465449184179306, Accuracy: 95.7378158569336, Test Loss: 0.15222862362861633, Test Accuracy: 95.19193267822266\n",
      "Epoch 4, Loss: 0.14514325559139252, Accuracy: 95.77742004394531, Test Loss: 0.15036045014858246, Test Accuracy: 95.24897003173828\n",
      "Epoch 4, Loss: 0.14350534975528717, Accuracy: 95.82441711425781, Test Loss: 0.14860899746418, Test Accuracy: 95.30440521240234\n",
      "Epoch 4, Loss: 0.14182156324386597, Accuracy: 95.87195587158203, Test Loss: 0.1470840573310852, Test Accuracy: 95.3499984741211\n",
      "Epoch 4, Loss: 0.14027713239192963, Accuracy: 95.91577911376953, Test Loss: 0.1453794687986374, Test Accuracy: 95.4034423828125\n",
      "Epoch 4, Loss: 0.13861629366874695, Accuracy: 95.96228790283203, Test Loss: 0.14382071793079376, Test Accuracy: 95.45338439941406\n",
      "Epoch 4, Loss: 0.13706286251544952, Accuracy: 96.00728607177734, Test Loss: 0.14217668771743774, Test Accuracy: 95.50587463378906\n",
      "Epoch 4, Loss: 0.13574188947677612, Accuracy: 96.04280853271484, Test Loss: 0.14057110249996185, Test Accuracy: 95.55765533447266\n",
      "Epoch 4, Loss: 0.1342339813709259, Accuracy: 96.08806610107422, Test Loss: 0.13904313743114471, Test Accuracy: 95.60615539550781\n",
      "Epoch 4, Loss: 0.13284611701965332, Accuracy: 96.12609100341797, Test Loss: 0.13756869733333588, Test Accuracy: 95.65379333496094\n",
      "Epoch 4, Loss: 0.1314743608236313, Accuracy: 96.16390228271484, Test Loss: 0.13618502020835876, Test Accuracy: 95.6985092163086\n",
      "Epoch 4, Loss: 0.13026215136051178, Accuracy: 96.19586181640625, Test Loss: 0.13479427993297577, Test Accuracy: 95.74132537841797\n",
      "Epoch 4, Loss: 0.1292058527469635, Accuracy: 96.22547149658203, Test Loss: 0.13350960612297058, Test Accuracy: 95.78231811523438\n",
      "Epoch 4, Loss: 0.12788400053977966, Accuracy: 96.26107788085938, Test Loss: 0.13213996589183807, Test Accuracy: 95.82471466064453\n",
      "Epoch 4, Loss: 0.12677934765815735, Accuracy: 96.289794921875, Test Loss: 0.13087622821331024, Test Accuracy: 95.86408996582031\n",
      "Epoch 4, Loss: 0.12558045983314514, Accuracy: 96.3221435546875, Test Loss: 0.12961281836032867, Test Accuracy: 95.9040298461914\n",
      "Epoch 4, Loss: 0.12432678043842316, Accuracy: 96.35840606689453, Test Loss: 0.12845750153064728, Test Accuracy: 95.94000244140625\n",
      "Epoch 4, Loss: 0.12317957729101181, Accuracy: 96.38847351074219, Test Loss: 0.12722912430763245, Test Accuracy: 95.977294921875\n",
      "Epoch 4, Loss: 0.12210603803396225, Accuracy: 96.42327117919922, Test Loss: 0.12600567936897278, Test Accuracy: 96.01546478271484\n",
      "Epoch 4, Loss: 0.12091568857431412, Accuracy: 96.45755004882812, Test Loss: 0.12485204637050629, Test Accuracy: 96.05184173583984\n",
      "Epoch 5, Loss: 0.1201324462890625, Accuracy: 96.48046875, Test Loss: 0.12379399687051773, Test Accuracy: 96.08428192138672\n",
      "Epoch 5, Loss: 0.11912453919649124, Accuracy: 96.50703430175781, Test Loss: 0.12285900115966797, Test Accuracy: 96.11422729492188\n",
      "Epoch 5, Loss: 0.1180400475859642, Accuracy: 96.53981018066406, Test Loss: 0.12184834480285645, Test Accuracy: 96.14582061767578\n",
      "Epoch 5, Loss: 0.11697318404912949, Accuracy: 96.57015228271484, Test Loss: 0.12077116221189499, Test Accuracy: 96.17862701416016\n",
      "Epoch 5, Loss: 0.11591845750808716, Accuracy: 96.60050964355469, Test Loss: 0.11975686252117157, Test Accuracy: 96.21086883544922\n",
      "Epoch 5, Loss: 0.11496260017156601, Accuracy: 96.62854766845703, Test Loss: 0.11901713907718658, Test Accuracy: 96.23268127441406\n",
      "Epoch 5, Loss: 0.11389992386102676, Accuracy: 96.65975189208984, Test Loss: 0.11802587658166885, Test Accuracy: 96.26277160644531\n",
      "Epoch 5, Loss: 0.11302314698696136, Accuracy: 96.6844711303711, Test Loss: 0.11704868823289871, Test Accuracy: 96.29368591308594\n",
      "Epoch 5, Loss: 0.11207833886146545, Accuracy: 96.71124267578125, Test Loss: 0.11608551442623138, Test Accuracy: 96.32294464111328\n",
      "Epoch 5, Loss: 0.11113417148590088, Accuracy: 96.73439025878906, Test Loss: 0.11518052965402603, Test Accuracy: 96.35150909423828\n",
      "Epoch 5, Loss: 0.11024708300828934, Accuracy: 96.76067352294922, Test Loss: 0.11424291878938675, Test Accuracy: 96.38068389892578\n",
      "Epoch 5, Loss: 0.10944340378046036, Accuracy: 96.78125762939453, Test Loss: 0.11350926756858826, Test Accuracy: 96.4048843383789\n",
      "Epoch 5, Loss: 0.10862134397029877, Accuracy: 96.80675506591797, Test Loss: 0.11260659992694855, Test Accuracy: 96.43314361572266\n",
      "Epoch 5, Loss: 0.10782808810472488, Accuracy: 96.82990264892578, Test Loss: 0.11176736652851105, Test Accuracy: 96.45833587646484\n",
      "Epoch 5, Loss: 0.10709436237812042, Accuracy: 96.85077667236328, Test Loss: 0.11096002906560898, Test Accuracy: 96.48439025878906\n",
      "Epoch 5, Loss: 0.10631454735994339, Accuracy: 96.8732681274414, Test Loss: 0.11011072248220444, Test Accuracy: 96.51087188720703\n",
      "Epoch 5, Loss: 0.10557360202074051, Accuracy: 96.89388275146484, Test Loss: 0.10927727818489075, Test Accuracy: 96.5369873046875\n",
      "Epoch 5, Loss: 0.10479232668876648, Accuracy: 96.92017364501953, Test Loss: 0.10852766036987305, Test Accuracy: 96.55999755859375\n",
      "Epoch 5, Loss: 0.10394477099180222, Accuracy: 96.94320678710938, Test Loss: 0.10774722695350647, Test Accuracy: 96.58421325683594\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# use keras.datasets instead of tensorflow.datasets\n",
    "from tensorflow.keras import datasets, layers\n",
    "mnist = datasets.mnist\n",
    "\n",
    "learning_rate = 1e-4\n",
    "keep_prob_rate = 0.7\n",
    "max_epoch = 5\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(32, 7, activation='relu')\n",
    "        self.pool1 = layers.MaxPooling2D()\n",
    "        self.conv2 = layers.Conv2D(64, 5, activation='relu')\n",
    "        self.pool2 = layers.MaxPooling2D()\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.d1 = layers.Dense(1024, activation='relu')\n",
    "        self.dropout = layers.Dropout(1-keep_prob_rate)\n",
    "        self.d2 = layers.Dense(10)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.d2(x)\n",
    "\n",
    "model = MyModel()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for i, (images, labels) in enumerate(train_ds):\n",
    "        train_step(images, labels)\n",
    "        if i % 100 == 0:\n",
    "            for test_images, test_labels in test_ds:\n",
    "                test_step(test_images, test_labels)\n",
    "            template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "            print(template.format(epoch+1,\n",
    "                                  train_loss.result(),\n",
    "                                  train_accuracy.result()*100,\n",
    "                                  test_loss.result(),\n",
    "                                  test_accuracy.result()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
